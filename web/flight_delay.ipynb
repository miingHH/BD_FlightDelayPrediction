{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 시각: 2023.05.22 - 12:02:39\n"
     ]
    }
   ],
   "source": [
    "# 경고메세지 끄기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 프로그램 시간 측정\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "time_start =  time.time()\n",
    "print('시작 시각:', time.strftime('%Y.%m.%d - %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'just_fix_windows_console' from 'colorama' (C:\\Users\\joljo\\AppData\\Roaming\\Python\\Python310\\site-packages\\colorama\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\2023-1\\학부수업\\빅데이터처리\\항공기\\web\\flight_delay.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/2023-1/%ED%95%99%EB%B6%80%EC%88%98%EC%97%85/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%B2%98%EB%A6%AC/%ED%95%AD%EA%B3%B5%EA%B8%B0/web/flight_delay.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnaive_bayes\u001b[39;00m \u001b[39mimport\u001b[39;00m GaussianNB\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/2023-1/%ED%95%99%EB%B6%80%EC%88%98%EC%97%85/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%B2%98%EB%A6%AC/%ED%95%AD%EA%B3%B5%EA%B8%B0/web/flight_delay.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/2023-1/%ED%95%99%EB%B6%80%EC%88%98%EC%97%85/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%B2%98%EB%A6%AC/%ED%95%AD%EA%B3%B5%EA%B8%B0/web/flight_delay.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbayes_opt\u001b[39;00m \u001b[39mimport\u001b[39;00m BayesianOptimization\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/2023-1/%ED%95%99%EB%B6%80%EC%88%98%EC%97%85/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%B2%98%EB%A6%AC/%ED%95%AD%EA%B3%B5%EA%B8%B0/web/flight_delay.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n",
      "File \u001b[1;32mc:\\Users\\joljo\\anaconda3\\envs\\AI\\lib\\site-packages\\bayes_opt\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbayesian_optimization\u001b[39;00m \u001b[39mimport\u001b[39;00m BayesianOptimization, Events\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdomain_reduction\u001b[39;00m \u001b[39mimport\u001b[39;00m SequentialDomainReductionTransformer\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m UtilityFunction\n",
      "File \u001b[1;32mc:\\Users\\joljo\\anaconda3\\envs\\AI\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbayes_opt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstraint\u001b[39;00m \u001b[39mimport\u001b[39;00m ConstraintModel\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtarget_space\u001b[39;00m \u001b[39mimport\u001b[39;00m TargetSpace\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mevent\u001b[39;00m \u001b[39mimport\u001b[39;00m Events, DEFAULT_EVENTS\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m _get_default_logger\n",
      "File \u001b[1;32mc:\\Users\\joljo\\anaconda3\\envs\\AI\\lib\\site-packages\\bayes_opt\\target_space.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m ensure_rng, NotUniqueError\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m Colours\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_hashable\u001b[39m(x):\n",
      "File \u001b[1;32mc:\\Users\\joljo\\anaconda3\\envs\\AI\\lib\\site-packages\\bayes_opt\\util.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m norm\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimize\u001b[39;00m \u001b[39mimport\u001b[39;00m minimize\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcolorama\u001b[39;00m \u001b[39mimport\u001b[39;00m just_fix_windows_console\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macq_max\u001b[39m(ac, gp, y_max, bounds, random_state, constraint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, n_warmup\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m    A function to find the maximum of the acquisition function\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39m    :return: x_max, The arg max of the acquisition function.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'just_fix_windows_console' from 'colorama' (C:\\Users\\joljo\\AppData\\Roaming\\Python\\Python310\\site-packages\\colorama\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(csv_path, save_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(f'./{save_name}.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    print(save_name, 'Done.')\n",
    "\n",
    "csv_to_parquet('./train.csv', 'train')\n",
    "csv_to_parquet('./test.csv', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['Estimated_Departure_Time', 'Estimated_Arrival_Time'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(time):\n",
    "    if pd.isna(time):\n",
    "        return None\n",
    "    else:\n",
    "        hours = time // 100\n",
    "        minutes = time % 100\n",
    "        return hours * 60 + minutes\n",
    "\n",
    "train['Estimated_Departure_Time'] = train['Estimated_Departure_Time'].apply(convert_time)\n",
    "train['Estimated_Arrival_Time'] = train['Estimated_Arrival_Time'].apply(convert_time)\n",
    "test['Estimated_Departure_Time'] = test['Estimated_Departure_Time'].apply(convert_time)\n",
    "test['Estimated_Arrival_Time'] = test['Estimated_Arrival_Time'].apply(convert_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 데이터셋에서 결측값을 채우기 위해 EDT, EAT가 모두 결측값인 행이 제거된 test_filtered 사용\n",
    "test_filtered = test.dropna(subset=['Estimated_Departure_Time', 'Estimated_Arrival_Time'])\n",
    "\n",
    "#EDT, EAT가 모두 결측값인 행의 결측값 채우기 위해 test_filtered를 사용\n",
    "# Origin_Airport와 Destination_Airport로 그룹화합니다.\n",
    "grouped_df = test_filtered.groupby(['Origin_Airport', 'Destination_Airport'])\n",
    "\n",
    "# 각 그룹의 Estimated_Arrival_Time과 Estimated_Departure_Time 각각의 평균을 계산\n",
    "mean_departure = grouped_df['Estimated_Departure_Time'].mean()\n",
    "mean_arrival = grouped_df['Estimated_Arrival_Time'].mean()\n",
    "\n",
    "mean_departure_dict = mean_departure.reset_index().set_index(['Origin_Airport', 'Destination_Airport'])['Estimated_Departure_Time'].to_dict()\n",
    "mean_arrival_dict = mean_arrival.reset_index().set_index(['Origin_Airport', 'Destination_Airport'])['Estimated_Arrival_Time'].to_dict()\n",
    "\n",
    "print(\"Mean Departure Dictionary:\")\n",
    "print(mean_departure_dict)\n",
    "print(\"\\nMean Arrival Dictionary:\")\n",
    "print(mean_arrival_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_arrival_time_test(row):\n",
    "    if pd.isna(row['Estimated_Arrival_Time']) and pd.isna(row['Estimated_Departure_Time']):\n",
    "        key = (row['Origin_Airport'], row['Destination_Airport'])\n",
    "        if key in mean_arrival_dict:\n",
    "            return mean_arrival_dict[key]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return row['Estimated_Arrival_Time']\n",
    "\n",
    "# 결측치가 있는 행에서 계산된 값을 사용하여 Estimated_Arrival_Time을 채웁니다.\n",
    "test['Estimated_Arrival_Time'] = test.apply(fill_arrival_time_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 데이터에서 같은 Origin_Airport와 Destination_Airport 사이의 거리의 평균 계산\n",
    "mean_diff = train.groupby(['Origin_Airport', 'Destination_Airport']).apply(\n",
    "    lambda group: (group['Estimated_Arrival_Time'] - group['Estimated_Departure_Time']).mean()\n",
    ").to_dict()\n",
    "\n",
    "print(mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Origin_Airport와 Destination_Airport가 같고 Estimated_Departure_Time만 확인가능할 경우 공항사이 결리는 시간 평균 더하기\n",
    "def fill_arrival_time(row):\n",
    "    if pd.isna(row['Estimated_Arrival_Time']):\n",
    "        key = (row['Origin_Airport'], row['Destination_Airport'])\n",
    "        if key in mean_diff:\n",
    "            return (row['Estimated_Departure_Time'] + mean_diff[key])%1440 #시차계산\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return row['Estimated_Arrival_Time']\n",
    "\n",
    "# 결측치가 있는 행에서 계산된 값을 사용하여 Estimated_Arrival_Time을 채웁니다.\n",
    "train['Estimated_Arrival_Time'] = train.apply(fill_arrival_time, axis=1)\n",
    "test['Estimated_Arrival_Time'] = test.apply(fill_arrival_time, axis=1)\n",
    "\n",
    "print(train)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Origin_Airport와 Destination_Airport가 같고 Estimated_Arrival_Time만 확인가능할 경우 공항사이 결리는 시간 평균 빼기\n",
    "def fill_departure_time(row):\n",
    "    if pd.isna(row['Estimated_Departure_Time']):\n",
    "        key = (row['Origin_Airport'], row['Destination_Airport'])\n",
    "        if key in mean_diff:\n",
    "            return (row['Estimated_Arrival_Time'] - mean_diff[key])%1440 #시차계산\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return row['Estimated_Departure_Time']\n",
    "\n",
    "# 결측치가 있는 행에서 계산된 값을 사용하여 Estimated_Departure_Time을 채웁니다.\n",
    "train['Estimated_Departure_Time'] = train.apply(fill_departure_time, axis=1)\n",
    "test['Estimated_Departure_Time'] = test.apply(fill_departure_time, axis=1)\n",
    "\n",
    "print(train)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_mode_col = ['Origin_State','Destination_State','Airline','Carrier_Code(IATA)','Carrier_ID(DOT)']\n",
    "\n",
    "for col in NaN_mode_col:\n",
    "    mode = train[col].mode()[0]\n",
    "    train[col] = train[col].fillna(mode)\n",
    "    \n",
    "    if col in test.columns:\n",
    "        test[col] = test[col].fillna(mode)\n",
    "\n",
    "print('Nan_mode_Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_col = ['Origin_Airport', 'Origin_State', 'Destination_Airport', 'Destination_State', 'Airline', 'Carrier_Code(IATA)', 'Tail_Number']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train[i])\n",
    "    train[i]=le.transform(train[i])\n",
    "    \n",
    "    for label in np.unique(test[i]):\n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test[i]=le.transform(test[i])\n",
    "print('qual_col Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = train.dropna(subset=['Delay'])\n",
    "unlabeled = train[train['Delay'].isnull()]\n",
    "\n",
    "print(train.shape)\n",
    "print(labeled.shape)\n",
    "print(unlabeled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "# ==> column_number: {'Not_Delayed': 0, 'Delayed': 1}\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "labeled.loc[:, 'Delay_num'] = labeled['Delay'].apply(lambda x: to_number(x, column_number))\n",
    "# Delay 열의 값에 따라서, Not_Delayed면 0, Delayed면 1이 Delay_num 열에 저장됨\n",
    "print('Delay_num Done.')\n",
    "\n",
    "# 위 전체 과정은 아래 코드와 같은 의미임\n",
    "# labeled['Delay_num'] = labeled['Delay'].apply(lambda x: 1 if x == 'Delayed' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unlabeled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled['Not_Delay_per'] = labeled['Delay_num'].apply(lambda x: 1 if x == 0 else 0).astype('float64')\n",
    "labeled['Delay_per'] = labeled['Delay_num'].astype('float64')\n",
    "\n",
    "num_of_gugan = 20\n",
    "for i in range(num_of_gugan):\n",
    "    gugan_size = int(round(len(unlabeled)/num_of_gugan, 0))\n",
    "    L = gugan_size * i\n",
    "    R = gugan_size * (i+1)\n",
    "    \n",
    "    small_unlabeled = unlabeled.iloc[L:R]\n",
    "    \n",
    "    # 레이블이 있는 데이터의 입력 변수와 출력 변수를 각각 labeled_x와 labeled_y로 저장\n",
    "    labeled_x = labeled.drop(columns=['ID', 'Delay', 'Delay_num', 'Not_Delay_per', 'Delay_per'])\n",
    "    labeled_y = labeled['Delay_per']\n",
    "\n",
    "    # 레이블이 없는 데이터의 입력 변수를 unlabeled_x로 저장\n",
    "    unlabeled_x = small_unlabeled.drop(columns=['ID', 'Delay'])\n",
    "\n",
    "    # XGBoost 모델의 입력 데이터 형식인 DMatrix로 변환\n",
    "    dtrain = xgb.DMatrix(labeled_x, label=labeled_y)\n",
    "    dtest = xgb.DMatrix(unlabeled_x)\n",
    "\n",
    "    # XGBoost 모델의 목적 함수와 클래스 개수 설정\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(sample_submission.columns)\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(params, dtrain)\n",
    "    small_unlabeled[['Not_Delay_per','Delay_per']] = bst.predict(dtest)\n",
    "    labeled = pd.concat([labeled, small_unlabeled])\n",
    "    print(f'{i}: 구간 {L} ~ {R} 완료, labeled size: {len(labeled)}')\n",
    "\n",
    "#exclude = [0.0, 1.0]\n",
    "#filtered_data = [~np.isin(labeled['Delay_per'], exclude)]\n",
    "per_mean = np.mean(labeled['Delay_per'])\n",
    "labeled['Delay_num'] = labeled['Delay_num'].fillna((labeled['Delay_per'] > per_mean).astype(int))\n",
    "train = labeled\n",
    "print(train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최적 매개변수 저장\n",
    "# best_params = xgb_bo.max['params']\n",
    "\n",
    "# # 최적 매개변수 중 max_depth와 n_estimators를 정수로 변환\n",
    "# best_params['max_depth'] = int(best_params['max_depth'])\n",
    "# best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "# best_params['objective'] = 'multi:softprob'\n",
    "# best_params['num_class'] = len(sample_submission.columns)\n",
    "\n",
    "# # 최적 매개변수로 XGBoost 모델 훈련\n",
    "# bst = xgb.train(best_params, dtrain)\n",
    "\n",
    "\n",
    "# 레이블이 없는 데이터에 대한 예측값 저장\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# labeled와 unlabeled 데이터 프레임 연결하여 train 데이터 프레임 생성\n",
    "\n",
    "print(\"Delay_num.fill_na Done.\")\n",
    "print(\"Dataset pre-processing Complete.\")\n",
    "\n",
    "\n",
    "# #### 생성된 `unlabeled['Delay_per']` 열의 평균값을 기준으로 `['Delay_num']` 열의 결측값을 채워넣습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # 데이터 칼럼을 data_column 변수에 할당합니다.\n",
    "# data_column = unlabeled['Delay_per']\n",
    "\n",
    "# # 1000개의 구간으로 나눕니다.\n",
    "# counts, bins = np.histogram(data_column, bins=1000)\n",
    "\n",
    "# # bar chart를 그립니다.\n",
    "# plt.bar(bins[:-1], counts, width=np.diff(bins))\n",
    "\n",
    "# # 데이터들의 평균 값을 계산합니다.\n",
    "# top_20_percent = np.percentile(data_column, 80)\n",
    "\n",
    "# # 평균 값의 위치에 세로 선을 그립니다.\n",
    "# plt.axvline(top_20_percent, color='r', linestyle='dashed', linewidth=2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 평균값보다 크면 Delayed, 작으면 Not_Delayed로 판단해서 ['Delay_num']을 채워 넣음\n",
    "# train['Delay_num'] = train['Delay_num'].fillna((train['Delay_per'] > top_20_percent).astype(int))\n",
    "\n",
    "\n",
    "# #### 전처리가 완료된 데이터를 csv, parquet 형태로 저장합니다.\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "# 전처리 코드를 여러 번 실행 하지 않기 위해서 csv, parquet 형식으로 한번 분리하였음\n",
    "train_pre = pd.DataFrame(data=train, columns=train.columns, index=train.index)\n",
    "train_pre.to_csv('train_pre.csv', index=False)\n",
    "\n",
    "test_pre = pd.DataFrame(data=test, columns=test.columns, index=test.index)\n",
    "test_pre.to_csv('test_pre.csv', index=False)\n",
    "\n",
    "csv_to_parquet('./train_pre.csv', 'train_pre')\n",
    "csv_to_parquet('./test_pre.csv', 'test_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 이상 전처리 코드를 실행했다면, 이 셀부터 실행하면 됨\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train = pd.read_parquet('./train_pre.parquet')\n",
    "test = pd.read_parquet('./test_pre.parquet')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(columns=['ID', 'Delay', 'Delay_num', 'Not_Delay_per', 'Delay_per'])\n",
    "train_y = train['Delay_num']\n",
    "test_x = test.drop(columns=['ID'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[35]:\n",
    "\n",
    "\n",
    "train_x.info()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "train_y.sample(10)\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "test_x.info()\n",
    "\n",
    "\n",
    "# #### 2. 하이퍼 파라미터 튜닝을 수행합니다.¶\n",
    "# 베이지안 최적화를 사용하여 XGBoost 모델의 최적 매개변수를 찾습니다.\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "# XGBoost 모델의 입력 데이터 형식인 DMatrix로 변환\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "\n",
    "# XGBoost 모델의 목적 함수와 클래스 개수 설정\n",
    "params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': len(sample_submission.columns)\n",
    "}\n",
    "\n",
    "# XGBoost 모델의 교차 검증 함수 정의 (전처리 과정에 있는 함수 정의와 동일함)\n",
    "def xgb_cv(max_depth, learning_rate, n_estimators):\n",
    "    params = {\n",
    "        'max_depth': int(max_depth),\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators': int(n_estimators)\n",
    "    }\n",
    "    xgb_clf = xgb.XGBClassifier(**params)\n",
    "    cv_result = cross_val_score(xgb_clf, train_x, train_y, cv=3)\n",
    "    return cv_result.mean()\n",
    "\n",
    "# 베이지안 최적화 객체 생성\n",
    "xgb_bo = BayesianOptimization(xgb_cv, {\n",
    "    'max_depth': (3, 10),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'n_estimators': (100, 1000)\n",
    "})\n",
    "\n",
    "# 베이지안 최적화 수행\n",
    "xgb_bo.maximize()\n",
    "print(\"hyper-parameter tuning for model Done.\")\n",
    "\n",
    "\n",
    "# #### 3. 찾아낸 최적의 parameters를 이용해서, XGBoost 학습을 진행하여 모델을 훈련시킵니다.\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "# 최적 매개변수 저장\n",
    "best_params = xgb_bo.max['params']\n",
    "\n",
    "# 최적 매개변수 중 max_depth와 n_estimators를 정수로 변환\n",
    "best_params['max_depth'] = int(best_params['max_depth'])\n",
    "best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "\n",
    "# 목적 함수와 클래스 개수 설정\n",
    "best_params['objective'] = 'multi:softprob'\n",
    "best_params['num_class'] = len(sample_submission.columns)\n",
    "\n",
    "# 최적 매개변수로 XGBoost 모델 훈련\n",
    "bst = xgb.train(best_params, dtrain)\n",
    "# bst = xgb.train(params, dtrain)\n",
    "\n",
    "# 레이블이 없는 데이터에 대한 예측값 생성\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "\n",
    "# #### 4. 최종 제출 파일을 생성합니다.\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "# 예측값을 submission 데이터 프레임으로 저장\n",
    "submission = pd.DataFrame(data=y_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
    "\n",
    "# submission 데이터 프레임을 CSV 파일로 출력\n",
    "submission.to_csv('FlightDelayPrediction_submission_pre_tune.csv', index=True)\n",
    "\n",
    "\n",
    "# 해당 제출 파일으로, 2023년 04월 19일 21시 기준으로 0.635점으로 2등을 달성하였습니다.\n",
    "# ![image.png](attachment:image.png)\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "time_end = time.time()\n",
    "sec = (time_end - time_start)\n",
    "print(\"수행 시간:\", datetime.timedelta(seconds=sec))\n",
    "print('종료 시각:', time.strftime('%Y.%m.%d - %H:%M:%S'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
